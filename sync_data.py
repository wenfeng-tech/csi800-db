import os
import time
import akshare as ak
import pandas as pd
from supabase import create_client, Client
from datetime import datetime, timedelta
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½®åŒºåŸŸ ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
# è®¾ç½®å¹¶å‘ä¸‹è½½çš„çº¿ç¨‹æ•°ï¼Œå¯æ ¹æ®è¿è¡Œç¯å¢ƒçš„æ€§èƒ½å’Œç½‘ç»œçŠ¶å†µè°ƒæ•´ï¼ˆå»ºè®® 5-15 ä¹‹é—´ï¼‰
MAX_WORKERS = 10 

# --- æ•°æ®è·å–é€»è¾‘ (åŸºæœ¬ä¸å˜ï¼Œä½†å»é™¤äº†å†…éƒ¨é‡è¯•) ---
def get_stock_history(stock_code: str, stock_name: str, start_date: str) -> pd.DataFrame:
    """
    è·å–å•åªè‚¡ç¥¨å†å²æ•°æ®ã€‚ä¸ºæé«˜å¹¶å‘æ€§èƒ½ï¼Œå–æ¶ˆäº†å‡½æ•°å†…çš„é‡è¯•ã€‚
    ç”±è°ƒç”¨æ–¹å†³å®šæ˜¯å¦ä»¥åŠå¦‚ä½•é‡è¯•ã€‚
    """
    try:
        stock_hist_df = ak.stock_zh_a_hist(symbol=stock_code, period="daily", start_date=start_date, adjust="qfq")

        if not stock_hist_df.empty:
            stock_hist_df.rename(columns={
                'æ—¥æœŸ': 'trade_date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high',
                'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume'
            }, inplace=True)
            stock_hist_df['stock_code'] = stock_code
            stock_hist_df['stock_name'] = stock_name
            stock_hist_df['trade_date'] = pd.to_datetime(stock_hist_df['trade_date']).dt.strftime('%Y-%m-%d')
            
            required_columns = [
                'trade_date', 'stock_code', 'stock_name',
                'open', 'high', 'low', 'close', 'volume'
            ]
            return stock_hist_df[required_columns]
    except Exception as e:
        print(f"è­¦å‘Šï¼šè·å–è‚¡ç¥¨ {stock_code} ({stock_name}) æ•°æ®å¤±è´¥ - {e}")
    return pd.DataFrame()

# --- æ ¸å¿ƒåŒæ­¥å‡½æ•° (å¹¶å‘+æ‰¹é‡æ’å…¥) ---
def fetch_and_insert_stocks(supabase_client: Client, stock_info: dict, start_date: str):
    """
    ä½¿ç”¨å¹¶å‘æŠ€æœ¯è·å–è‚¡ç¥¨æ•°æ®ï¼Œå¹¶æ‰¹é‡æ’å…¥æ•°æ®åº“ã€‚
    Args:
        supabase_client: Supabaseå®¢æˆ·ç«¯å®ä¾‹ã€‚
        stock_info: åŒ…å« {ä»£ç : åç§°} çš„å­—å…¸ã€‚
        start_date: æ•°æ®å¼€å§‹æ—¥æœŸã€‚
    """
    all_data_frames = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘ä¸‹è½½
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # åˆ›å»ºæœªæ¥ä»»åŠ¡åˆ—è¡¨
        futures = {executor.submit(get_stock_history, code, name, start_date): (code, name) 
                   for code, name in stock_info.items()}

        total_stocks = len(stock_info)
        for i, future in enumerate(as_completed(futures)):
            code, name = futures[future]
            try:
                df = future.result()
                if not df.empty:
                    all_data_frames.append(df)
                    print(f"è¿›åº¦: {i + 1}/{total_stocks} | æˆåŠŸè·å– {code} ({name}) çš„ {len(df)} æ¡æ•°æ®ã€‚")
                else:
                    print(f"è¿›åº¦: {i + 1}/{total_stocks} | è‚¡ç¥¨ {code} ({name}) æœªè¿”å›æ•°æ®ã€‚")
            except Exception as e:
                print(f"è¿›åº¦: {i + 1}/{total_stocks} | å¤„ç†è‚¡ç¥¨ {code} ({name}) æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")

    if not all_data_frames:
        print("æœªè·å–åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®ï¼Œæ— éœ€æ’å…¥ã€‚")
        return

    # åˆå¹¶æ‰€æœ‰DataFrameå¹¶è¿›è¡Œæ‰¹é‡æ’å…¥
    full_df = pd.concat(all_data_frames, ignore_index=True)
    data_to_insert = full_df.to_dict(orient='records')
    
    print(f"\nå‡†å¤‡æ‰¹é‡æ’å…¥ {len(data_to_insert)} æ¡æ•°æ®...")
    try:
        # Supabase çš„ upsert å¯¹å¤§æ‰¹é‡æ•°æ®å¯èƒ½æœ‰é™åˆ¶ï¼Œå¯ä»¥è€ƒè™‘åˆ†æ‰¹
        # ä½†å¯¹äºå‡ ä¸‡åˆ°å‡ åä¸‡è¡Œé€šå¸¸æ˜¯æ²¡é—®é¢˜çš„
        supabase_client.table("csi800_daily_data").upsert(data_to_insert).execute()
        print(f"ğŸ‰ æˆåŠŸæ‰¹é‡åŒæ­¥ {len(all_data_frames)} åªè‚¡ç¥¨ï¼Œå…± {len(data_to_insert)} æ¡è®°å½•ã€‚")
    except Exception as e:
        print(f"æ•°æ®åº“é”™è¯¯ï¼šæ‰¹é‡æ’å…¥æ•°æ®å¤±è´¥ - {e}")

# --- æ–°å¢ï¼šæ ¡éªŒå’Œä¿®å¤é€»è¾‘ ---
def verify_and_retry_sync(supabase_client: Client):
    """ã€æ ¡éªŒä¿®å¤æ¨¡å¼ã€‘æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼Œå¹¶åªåŒæ­¥ç¼ºå¤±æˆ–è½åçš„è‚¡ç¥¨ã€‚"""
    print("å¼€å§‹æ‰§è¡Œæ•°æ®æ ¡éªŒä¸ä¿®å¤...")
    
    # 1. è·å–ç›®æ ‡è‚¡ç¥¨åˆ—è¡¨ (ä¸­è¯800)
    target_stocks = get_csi800_stock_info()
    if not target_stocks:
        print("æ— æ³•è·å–ç›®æ ‡è‚¡ç¥¨åˆ—è¡¨ï¼Œæ ¡éªŒä»»åŠ¡ç»ˆæ­¢ã€‚")
        return
    
    target_stock_codes = set(target_stocks.keys())
    print(f"ç›®æ ‡åŒæ­¥ {len(target_stock_codes)} åªä¸­è¯800æˆåˆ†è‚¡ã€‚")

    # 2. ä»æ•°æ®åº“è·å–å½“å‰æ•°æ®çŠ¶æ€
    try:
        # ä½¿ç”¨rpcè°ƒç”¨æ‚¨æä¾›çš„SQLå‡½æ•°ï¼Œå‡è®¾æ‚¨å·²åœ¨Supabaseåå°åˆ›å»ºäº†å®ƒ
        # å¦‚æœæ²¡æœ‰åˆ›å»ºSQLå‡½æ•°ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨pythonç«¯è¿›è¡Œæ•°æ®å¤„ç†
        response = supabase_client.table("csi800_daily_data").select("stock_code, trade_date").execute()
        db_data = pd.DataFrame(response.data)
        if db_data.empty:
             print("æ•°æ®åº“ä¸­æ— æ•°æ®ï¼Œå°†åŒæ­¥æ‰€æœ‰è‚¡ç¥¨ã€‚")
             stocks_to_retry = target_stocks
        else:
            db_summary = db_data.groupby('stock_code')['trade_date'].max().to_dict()
            print(f"æ•°æ®åº“ä¸­å·²æœ‰ {len(db_summary)} åªè‚¡ç¥¨çš„æ•°æ®ã€‚")

            # 3. æ‰¾å‡ºéœ€è¦é‡è¯•çš„è‚¡ç¥¨
            # æ¡ä»¶1ï¼šæ•°æ®åº“é‡Œæ ¹æœ¬æ²¡æœ‰çš„è‚¡ç¥¨
            # æ¡ä»¶2ï¼šæ•°æ®åº“é‡Œæœ€æ–°æ—¥æœŸæ—©äºNå¤©å‰çš„è‚¡ç¥¨ï¼ˆä¾‹å¦‚3å¤©å‰ï¼‰
            stocks_to_retry = {}
            latest_trading_day_threshold = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')

            for code, name in target_stocks.items():
                if code not in db_summary:
                    stocks_to_retry[code] = name # ç¼ºå¤±çš„è‚¡ç¥¨
                elif db_summary[code] < latest_trading_day_threshold:
                    stocks_to_retry[code] = name # æ•°æ®è½åçš„è‚¡ç¥¨
            
    except Exception as e:
        print(f"ä»Supabaseè·å–æ•°æ®çŠ¶æ€å¤±è´¥: {e}ã€‚å°†å°è¯•åŒæ­¥æ‰€æœ‰è‚¡ç¥¨ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆã€‚")
        stocks_to_retry = target_stocks

    if not stocks_to_retry:
        print("âœ… æ•°æ®æ ¡éªŒå®Œæˆï¼Œæ‰€æœ‰è‚¡ç¥¨æ•°æ®éƒ½æ˜¯æœ€æ–°çš„ã€‚")
        return

    print(f"å‘ç° {len(stocks_to_retry)} åªè‚¡ç¥¨éœ€è¦åŒæ­¥/ä¿®å¤ã€‚åˆ—è¡¨: {list(stocks_to_retry.keys())}")
    
    # ä½¿ç”¨ä¸ä¸»ä»»åŠ¡ç›¸åŒçš„å¹¶å‘é€»è¾‘ï¼Œä½†åªå¤„ç†éœ€è¦é‡è¯•çš„è‚¡ç¥¨
    # å¯¹äºä¿®å¤ä»»åŠ¡ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›è·å–æœ€è¿‘ä¸€æ®µæ—¶é—´çš„æ•°æ®ï¼Œæ¯”å¦‚æœ€è¿‘ä¸€å¹´
    start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
    fetch_and_insert_stocks(supabase_client, stocks_to_retry, start_date)
    print("ğŸš€ æ ¡éªŒä¸ä¿®å¤ä»»åŠ¡å®Œæˆï¼")


def get_csi800_stock_info() -> dict:
    # (æ­¤å‡½æ•°ä¸æ‚¨åŸæ¥çš„ä¸€æ ·ï¼Œæ— éœ€æ”¹åŠ¨)
    try:
        stock_df = ak.index_stock_cons_csindex(symbol="000906")
        print(f"æˆåŠŸä»ä¸­è¯æŒ‡æ•°å®˜ç½‘è·å–ä¸­è¯800æˆåˆ†è‚¡ï¼Œå…± {len(stock_df)} åªè‚¡ç¥¨ã€‚")
        return pd.Series(stock_df['æˆåˆ†åˆ¸åç§°'].values, index=stock_df['æˆåˆ†åˆ¸ä»£ç ']).to_dict()
    except Exception as e:
        print(f"é”™è¯¯ï¼šè·å–ä¸­è¯800æˆåˆ†è‚¡åˆ—è¡¨å¤±è´¥ - {e}")
        return {}

# --- ä¸»é€»è¾‘å…¥å£ ---
def main():
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("å…³é”®é…ç½®ç¼ºå¤±ï¼šè¯·è®¾ç½® SUPABASE_URL å’Œ SUPABASE_KEY ç¯å¢ƒå˜é‡ã€‚")

    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    sync_mode = sys.argv[1] if len(sys.argv) > 1 else 'daily'
    print(f"--- å½“å‰è¿è¡Œæ¨¡å¼: {sync_mode} ---")

    if sync_mode == 'daily':
        print("æ‰§è¡Œæ¯æ—¥å¢é‡æ›´æ–°...")
        stock_info = get_csi800_stock_info()
        if stock_info:
            start_date = (datetime.now() - timedelta(days=5)).strftime('%Y%m%d')
            fetch_and_insert_stocks(supabase, stock_info, start_date)
    
    elif sync_mode == 'verify':
        verify_and_retry_sync(supabase)

    elif sync_mode in ['full', 'partial']:
        start_dates = {'full': "20050101", 'partial': "20150101"}
        print(f"æ‰§è¡Œå†å²æ•°æ®åŒæ­¥ ({sync_mode})...")
        stock_info = get_csi800_stock_info()
        if stock_info:
            fetch_and_insert_stocks(supabase, stock_info, start_dates[sync_mode])

    else:
        print(f"é”™è¯¯ï¼šæ— æ³•è¯†åˆ«çš„æ¨¡å¼ '{sync_mode}'ã€‚è¯·é€‰æ‹© 'full', 'partial', 'daily' æˆ– 'verify'ã€‚")

if __name__ == "__main__":
    main()
